"""
Script to show the benefit of eye motions.

(1) Spikes generated by no motion.
(2) Spikes generated including motion.

See which case it is easier to reconstruct the image.
"""

import numpy as np
from scipy.io import loadmat
from argparse import ArgumentParser

from itertools import product

from src.model import EMBurak
from utils.image_gen import ImageGenerator

parser = ArgumentParser('Test the motion benefit')
parser.add_argument('--n_repeats', type=int, default=5,
                    help='Number of repetitions for each set of parameters.')
parser.add_argument('--n_t', type=int, default=100,
                    help='Number of timesteps')
parser.add_argument('--output_dir', type=str, default='motion_benefit',
                    help='Output_directory')
parser.add_argument('--dc', type=float, default=20.,
                    help='Diffusion Constant for eye motion')
parser.add_argument('--image', type=str, default='e',
                    help='Digit type')
parser.add_argument('--ds', type=float, default=0.4,
                    help='Pixel Spacing')

args = parser.parse_args()

n_itr = args.n_t / 5

if args.image == 'e':
    L_I = 20
    ig = ImageGenerator(L_I)
    ig.make_big_e()
    ig.normalize()
    D = np.eye(L_I ** 2)
    from utils.block_prior import block_prior
    D = 0.25 * block_prior(L_I / 2)
elif args.image == 'mnist':
    # Sparse coding dictionary prior
    data = loadmat('sparse_coder/output/mnist_dictionary.mat')
    D = data['D']
    _, N_pix = D.shape
    L_I = int(np.sqrt(N_pix))  # Linear dimension of image
    ig = ImageGenerator(L_I)
    ig.make_digit()
    ig.normalize()
else:
    raise ValueError('Unrecognized image: {}'.format(args.image))

motion_info_ = [
    #  ({'mode': 'Diffusion', 'dc': args.dc},
    #   {'mode': 'PositionDiffusion', 'dc': args.dc}),
    ({'mode': 'Experiment', 'fpath': 'data/paths.mat'},
     {'mode': 'PositionDiffusion', 'dc': 20.}),
    ({'mode': 'Diffusion', 'dc': 0.0001},
     {'mode': 'PositionDiffusion', 'dc': 20.})
]

#  motion_info_ = motion_info_[1:2]
#  motion_info_ = [
#      ({'mode': 'Diffusion', 'dc': 0.001},
#       {'mode': 'PositionDiffusion', 'dc': dc_infer})
#      for dc_infer in [0.01, 0.4, 2., 20., 100.]]

#  ds_ = [args.ds]
#  ds_ = [0.32, 0.4, 0.6]
ds_ = [0.40]
de = 1.09

for (motion_gen, motion_prior), ds in product(motion_info_, ds_):
    emb = EMBurak(
        ig.img, D, motion_gen, motion_prior, n_t=args.n_t, save_mode=True,
        s_gen_name=ig.img_name, ds=ds, neuron_layout='hex', fista_c=0.8,
        de=de, l_n=8.1, n_itr=n_itr, lamb=0.0, tau=1.28, n_g_itr=320,
        output_dir_base=args.output_dir, print_mode=True)
    #  for _ in range(args.n_repeats):
    #      XR, YR, R = emb.gen_data(ig.img)
    #      emb.run_inference_true_path(R, XR, YR)
    #      emb.save()
    #      emb.reset()
    for _ in range(args.n_repeats):
        XR, YR, R = emb.gen_data(ig.img)
        emb.run_em(R)
        emb.save()
        emb.reset()

# convert -set delay 30 -colorspace GRAY
# -colors 256 -dispose 1 -loop 0 -scale 50% *.png alg_performance.gif

# convert -set delay 30 -colors 256
# -dispose 1 -loop 0 *.jpg alg_performance.gif
